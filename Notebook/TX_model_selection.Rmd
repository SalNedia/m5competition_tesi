---
title: "R Notebook"
output:
---

In questo caso viene analizzata la serie di secondo livello relativa allo stato TX

```{r}
source("models.R")

sales_states <- read.csv("sales_states.csv")
df_sales_states<- as.data.frame(sales_states)
calendar <- read.csv("calendar.csv",header = TRUE)
df_calendar<- as.data.frame(calendar)
df_calendar<-df_calendar[1:1913,]

df_sales_states<-cbind(df_sales_states,df_calendar$date)
df_sales_states_train<-head(df_sales_states, n=(nrow(df_sales_states)-28))
df_sales_states_test<-tail(df_sales_states, n=28)
```

## Seasonal naive
Il primo modello valutato è il seasonal naive

```{r}
df_TX<-data.frame(df_sales_states_train$`df_calendar$date`,df_sales_states_train$TX)
names(df_TX)<-c("Date","Y")
list_of_frames <- expanding(df_TX, 1240, step=28) #1210=circa 3 anni e mezzo
results_snaive<-cross_validation(list_of_frames, horizon=28, frequency=7, fit_snaive, plot=TRUE)
```
```{r}
results_snaive$error
```

## ARIMA
Il secondo modello è l'ARIMA:
```{r}
# fit arima no xreg
results_arima<-cross_validation(list_of_frames, horizon=28, frequency=7, fit_arima, plot=TRUE)
```

```{r}
results_arima$error
```

## ETS
Il terzo modello è l'Exponential Smoothing (ETS)
```{r}
results_ets<-cross_validation(list_of_frames, horizon=28, frequency=7, fit_ets, plot=TRUE)
```

```{r}
results_ets$error
```

## NAR
Il quarto modello è il NAR (Non-linear autoregression model):
```{r}
results_nar<-cross_validation(list_of_frames, horizon=28, frequency=7, fit_nnetar, plot=TRUE)
```

```{r}
results_nar$error
```

## Modelli con variabili esterne
I modelli successivi utilizzano invece le variabili esterne, in questo caso in particolare sono state aggiunte le informazioni presenti in calendar.csv
```{r}
#ora i modelli con variabli esterne:
df_calendar_train<-head(df_calendar, n=(nrow(df_calendar)-28))
df_calendar_test<-tail(df_calendar, n=28)
df_TX <- cbind(df_TX,df_calendar_train$wday,df_calendar_train$month,df_calendar_train$snap_CA,df_calendar_train$snap_TX,df_calendar_train$snap_WI)
df_TX
```
## NARX
Il primo modello è il NAR model with exogenous variables (NARX):
```{r}
list_of_frames <- expanding(df_TX, 1240, step=28) #1210=circa 3 anni e mezzo
results_narx<-cross_validation(list_of_frames, horizon=28, frequency=7, fit_nnetar_xreg, plot=TRUE)
```

```{r}
results_narx$error
```
##ARIMAX
Il secondo modello è l'ARIMA model with exogeneous variables (ARIMAX):
```{r}
results_arimax<-cross_validation(list_of_frames, horizon=28, frequency=7, fit_arima_errors, plot=TRUE)
```

```{r}
results_arimax$error
```
## Combinazione di modelli

Infine le combinazioni dei modelli più interessanti:

La prima combinazione è quella tra arima e neural network con xreg utilizzando la media:
```{r}
results_avg_arima_nar<-cross_validation(list_of_frames, horizon=28, frequency=7, fit_combination_xreg_average, plot=TRUE)
```

```{r}
results_avg_arima_nar$error
```

La seconda combinazione è quella tra arima e neural network con xreg utilizzando cls:
```{r}
results_cls_arima_nar<-cross_validation(list_of_frames, horizon=28, frequency=7, fit_combination_xreg_cls, plot=TRUE)
```

```{r}
results_cls_arima_nar$error
```

La terza combinazione è quella tra arima,neural network con xreg e ets utilizzando la media:
```{r}
results_avg_comb<-cross_validation(list_of_frames, horizon=28, frequency=7, fit_combination_average, plot=TRUE)
```

```{r}
results_avg_comb$error
```
Infine l'tultima combinazione è quella tra arima,neural network con xreg e ets utilizzando cls:
```{r}
results_cls_comb<-cross_validation(list_of_frames, horizon=28, frequency=7, fit_combination_cls, plot=TRUE)
```

```{r}
results_cls_comb$error
```

##Risultati

```{r}
models_name<-c("snaive","arima","ets","nar","narx","arimax","avg_arima_nar","cls_arima_nar","avg_comb","cls_comb")
errors<-rbind(results_snaive$error, 
                 results_arima$error,
                 results_ets$error,
                 results_nar$error,
                 results_narx$error,
                 results_arimax$error,
                 results_avg_arima_nar$error,
                 results_cls_arima_nar$error,
                 results_avg_comb$error,
                 results_avg_comb$error)
df_errors<-data.frame(models_name,errors)
df_errors
```

Confrontando i vari modelli, sulla metrica della competition (RMSSE), quello che ha ottenuto prestazioni migliori, in termini di valori medi di RMSSE, è il NAR model con variabili esterne.
